{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân đoạn hình ảnh bằng DBSCAN và đánh giá hiệu suất\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import random\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import directed_hausdorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Định nghĩa hàm hiển thị và đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(idxs, image_files=None, images=None):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    if image_files is not None:\n",
    "        for i, idx in enumerate(idxs):\n",
    "            img = cv2.imread(image_files[idx])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Ảnh {i+1}\")\n",
    "    elif images is not None:\n",
    "        for i in range(len(idxs)):\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Ảnh {i+1}\")\n",
    "    else:\n",
    "        raise ValueError(\"Cần cung cấp ít nhất một trong hai tham số: image_files hoặc images\")\n",
    "    plt.show()\n",
    "\n",
    "# Hàm tính Dice Coefficient\n",
    "def dice_coefficient(pred, gt):\n",
    "    pred = pred.flatten()\n",
    "    gt = gt.flatten()\n",
    "    intersection = np.sum(pred * gt)\n",
    "    return (2. * intersection) / (np.sum(pred) + np.sum(gt) + 1e-8)\n",
    "\n",
    "# Hàm tính IoU\n",
    "def iou(pred, gt):\n",
    "    pred = pred.flatten()\n",
    "    gt = gt.flatten()\n",
    "    intersection = np.sum(pred * gt)\n",
    "    union = np.sum(pred) + np.sum(gt) - intersection\n",
    "    return intersection / (union + 1e-8)\n",
    "\n",
    "# Hàm tính Precision, Recall\n",
    "def precision_recall(pred, gt):\n",
    "    pred = pred.flatten()\n",
    "    gt = gt.flatten()\n",
    "    tp = np.sum(pred * gt)\n",
    "    fp = np.sum(pred * (1 - gt))\n",
    "    fn = np.sum((1 - pred) * gt)\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    return precision, recall\n",
    "\n",
    "# Hàm tính Hausdorff Distance\n",
    "def hausdorff_distance(pred, gt):\n",
    "    pred_points = np.argwhere(pred > 0)\n",
    "    gt_points = np.argwhere(gt > 0)\n",
    "    if len(pred_points) == 0 or len(gt_points) == 0:\n",
    "        return np.inf\n",
    "    return max(directed_hausdorff(pred_points, gt_points)[0], directed_hausdorff(gt_points, pred_points)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'./Brain Tumor Segmentation Dataset/image'\n",
    "image_files = []\n",
    "ground_truth_dir = r'./Brain Tumor Segmentation Dataset/mask'\n",
    "\n",
    "for folder in ['0', '1', '2', '3']:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "        if files:\n",
    "            random_file = random.choice(files)\n",
    "            image_files.append(os.path.join(folder_path, random_file))\n",
    "\n",
    "print(f\"Số lượng ảnh đã chọn: {len(image_files)}\")\n",
    "print(\"Các ảnh đã chọn:\")\n",
    "showImages(range(len(image_files)), image_files=image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = []\n",
    "for idx in range(len(image_files)):\n",
    "    gray_img = cv2.imread(image_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    gray_images.append(gray_img)\n",
    "\n",
    "print(\"4 ảnh xám:\")\n",
    "showImages(range(len(gray_images)), images=gray_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images = []\n",
    "size = (192, 192)\n",
    "for img in gray_images:\n",
    "    resized_img = cv2.resize(img, size, cv2.INTER_AREA)\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "print(\"4 ảnh xám đã resize:\")\n",
    "showImages(range(len(resized_images)), images=resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_images = []\n",
    "for img in resized_images:\n",
    "    equalized_img = cv2.equalizeHist(img)\n",
    "    equalized_images.append(equalized_img)\n",
    "\n",
    "print(\"4 ảnh xám đã cân bằng histogram:\")\n",
    "showImages(range(len(equalized_images)), images=equalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_images = []\n",
    "for img in equalized_images:\n",
    "    blurred_img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    blurred_images.append(blurred_img)\n",
    "print(\"4 ảnh xám đã làm mịn:\")\n",
    "showImages(range(len(blurred_images)), images=blurred_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Định nghĩa hàm phân đoạn DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEps(X_scaled):\n",
    "    k = 10\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(X_scaled)\n",
    "    distances, _ = neigh.kneighbors(X_scaled)\n",
    "    distances = np.sort(distances[:, k-1], axis=0)\n",
    "    kneedle = KneeLocator(range(len(distances)), distances, curve=\"convex\", direction=\"increasing\")\n",
    "    knee_eps = kneedle.knee_y\n",
    "    print(f\"Estimated eps: {knee_eps:.3f}\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(distances, label='k-distance')\n",
    "    plt.axhline(y=knee_eps, color='r', linestyle='--', label=f'Estimated eps = {knee_eps:.3f}')\n",
    "    plt.title(f\"k-distance Graph (k={k})\")\n",
    "    plt.xlabel(\"Points (sorted)\")\n",
    "    plt.ylabel(f\"Distance to {k}th Nearest Neighbor\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return knee_eps\n",
    "\n",
    "def find_best_min_samples(X_scaled, eps, min_samples_range):\n",
    "    best_score = -1\n",
    "    best_min_samples = None\n",
    "    silhouette_scores = []\n",
    "    for min_samples in min_samples_range:\n",
    "        labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        if n_clusters >= 2:\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            silhouette_scores.append((min_samples, score))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_min_samples = min_samples\n",
    "    return best_min_samples, silhouette_scores\n",
    "\n",
    "def evaluate_unsupervised(X_scaled, labels):\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    metrics = {}\n",
    "    if n_clusters >= 2:\n",
    "        metrics['Silhouette Score'] = silhouette_score(X_scaled, labels)\n",
    "        metrics['Davies-Bouldin Index'] = davies_bouldin_score(X_scaled, labels)\n",
    "        metrics['Calinski-Harabasz Index'] = calinski_harabasz_score(X_scaled, labels)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thực thi DBSCAN và đánh giá hiệu suất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "evaluation_results = []\n",
    "\n",
    "for i, img in enumerate(blurred_images):\n",
    "    print(f\"\\n=== Ảnh {i+1} ===\")\n",
    "    h, w = img.shape\n",
    "    X = np.column_stack((np.indices((h, w)).reshape(2, -1).T, img.flatten()))\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Tìm eps tối ưu\n",
    "    eps = getEps(X_scaled)\n",
    "\n",
    "    # Tìm min_samples tối ưu\n",
    "    min_samples_range = range(10, 300, 10)\n",
    "    best_min_samples, scores = find_best_min_samples(X_scaled, eps, min_samples_range)\n",
    "    print(f\"→ eps tối ưu = {eps:.2f}, min_samples tối ưu = {best_min_samples}\")\n",
    "\n",
    "    # Áp dụng DBSCAN\n",
    "    labels = DBSCAN(eps=eps, min_samples=best_min_samples).fit_predict(X_scaled)\n",
    "    label_img = labels.reshape(h, w)\n",
    "    final_results.append((img, label_img))\n",
    "\n",
    "    # Đánh giá không giám sát\n",
    "    metrics_unsupervised = evaluate_unsupervised(X_scaled, labels)\n",
    "    print(\"Đánh giá không giám sát:\")\n",
    "    for metric, value in metrics_unsupervised.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Đánh giá giám sát (nếu có ground truth)\n",
    "    base_name, ext = os.path.splitext(image_files[i])\n",
    "    ground_truth_path = f\"{base_name}_m{ext}\"\n",
    "    if os.path.exists(ground_truth_path):\n",
    "        gt = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt = cv2.resize(gt, size, cv2.INTER_AREA)\n",
    "        metrics_supervised = evaluate_supervised(label_img, gt)\n",
    "        print(\"Đánh giá giám sát:\")\n",
    "        for metric, value in metrics_supervised.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        evaluation_results.append((metrics_unsupervised, metrics_supervised))\n",
    "    else:\n",
    "        print(f\"Không tìm thấy ground truth tại: {ground_truth_path}, chỉ đánh giá không giám sát.\")\n",
    "        evaluation_results.append((metrics_unsupervised, None))\n",
    "\n",
    "    # Hiển thị kết quả\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(\"Ảnh gốc\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(label_img, cmap='jet')\n",
    "    plt.title(\"Kết quả DBSCAN\")\n",
    "    plt.axis('off')\n",
    "    if os.path.exists(ground_truth_path):\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(gt, cmap='gray')\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
